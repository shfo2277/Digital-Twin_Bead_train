#import tensorflow as tf
import torch
import platform
import subprocess
import sys

# print("ğŸ“Œ Python ì •ë³´")
# print("Python ë²„ì „:", platform.python_version())

# print("\nğŸ“Œ TensorFlow ì •ë³´")
# print("TensorFlow ë²„ì „:", tf.__version__)
# print("GPU ì‚¬ìš© ê°€ëŠ¥:", tf.config.list_physical_devices('GPU'))

# print("\nğŸ“Œ PyTorch ì •ë³´")
# print("PyTorch ë²„ì „:", torch.__version__)
# print("CUDA ì‚¬ìš© ê°€ëŠ¥:", torch.cuda.is_available())
# if torch.cuda.is_available():
#     print("ì‚¬ìš© ì¤‘ì¸ GPU:", torch.cuda.get_device_name(0))
#     print("CUDA ë²„ì „ (torch):", torch.version.cuda)
#     print("cuDNN ë²„ì „ (torch):", torch.backends.cudnn.version())

# print("\nğŸ“Œ NVIDIA ë“œë¼ì´ë²„ ë° CUDA í™•ì¸ (nvidia-smi)")
# try:
#     output = subprocess.check_output(['nvidia-smi'], encoding='utf-8')
#     print(output)
# except FileNotFoundError:
#     print("âŒ nvidia-smi ëª…ë ¹ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. NVIDIA ë“œë¼ì´ë²„ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
# except Exception as e:
#     print("nvidia-smi ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜:", e)


import platform
import subprocess
import sys

print("Python ì •ë³´")
print("Python ë²„ì „:", platform.python_version())

# # TensorFlow í™•ì¸
# try:
#     import tensorflow as tf
#     print("\nğŸ“Œ TensorFlow ì •ë³´")
#     print("TensorFlow ë²„ì „:", tf.__version__)
#     print("GPU ì‚¬ìš© ê°€ëŠ¥:", tf.config.list_physical_devices('GPU'))
# except ImportError:
#     print("\nğŸ“Œ TensorFlow ì •ë³´")
#     print("âŒ TensorFlowê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")

# PyTorch í™•ì¸
try:
    import torch
    print("\n PyTorch ì •ë³´")
    print("PyTorch ë²„ì „:", torch.__version__)
    print("torchvision ë²„ì „:", __import__('torchvision').__version__)
    print("CUDA ì‚¬ìš© ê°€ëŠ¥:", torch.cuda.is_available())
    if torch.cuda.is_available():
        print("ì‚¬ìš© ì¤‘ì¸ GPU:", torch.cuda.get_device_name(0))
        print("CUDA ë²„ì „ (torch):", torch.version.cuda)
        print("cuDNN ë²„ì „ (torch):", torch.backends.cudnn.version())
except ImportError:
    print("\n PyTorch ì •ë³´")
    print("!!!!!!! PyTorchê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")

# NVIDIA ë“œë¼ì´ë²„ ë° CUDA
print("\n NVIDIA ë“œë¼ì´ë²„ ë° CUDA í™•ì¸ (nvidia-smi)")
try:
    output = subprocess.check_output(['nvidia-smi'], encoding='utf-8')
    print(output)
except FileNotFoundError:
    print(" nvidia-smi ëª…ë ¹ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. NVIDIA ë“œë¼ì´ë²„ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
except Exception as e:
    print("nvidia-smi ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜:", e)

# ìµœì¢… ì¢…í•© íŒë‹¨
print("\n@@@@@ ìµœì¢… GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ ìš”ì•½")
gpu_tf = False
gpu_torch = False

try:
    if tf.config.list_physical_devices('GPU'):
        gpu_tf = True
except:
    pass

try:
    if torch.cuda.is_available():
        gpu_torch = True
except:
    pass

if gpu_tf or gpu_torch:
    print("ğŸ‰ GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    if gpu_tf:
        print("âœ” TensorFlowì—ì„œ GPU ì‚¬ìš© ê°€ëŠ¥")
    if gpu_torch:
        print("âœ” PyTorchì—ì„œ GPU ì‚¬ìš© ê°€ëŠ¥")
else:
    print("âš  GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„¤ì¹˜ ë˜ëŠ” í™˜ê²½ êµ¬ì„±ì„ í™•ì¸í•˜ì„¸ìš”.")
